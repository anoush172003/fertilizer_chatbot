{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361816cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "data = pd.read_excel(r\"C:\\Users\\Admin\\Desktop\\KT\\NPK.xlsx\")\n",
    "\n",
    "# Splitting the data into input and output variables\n",
    "X = data.iloc[:, :3]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "lr = LogisticRegression(random_state=0)\n",
    "knn=KNeighborsClassifier()\n",
    "nb=GaussianNB()\n",
    "dtc.fit(X, y)\n",
    "nb.fit(X, y)\n",
    "knn.fit(X, y)\n",
    "lr.fit(X, y)\n",
    "rfc.fit(X, y)\n",
    "\n",
    "N = input(\"Enter the value for N: \")\n",
    "K = input(\"Enter the value for K: \")\n",
    "P = input(\"Enter the value for P: \")\n",
    "\n",
    "N = int(N)\n",
    "K = int(K)\n",
    "P = int(P)\n",
    "\n",
    "# User inputs\n",
    "user_input = [[N,K,P]]\n",
    "\n",
    "prediction_dtc = dtc.predict(user_input)\n",
    "prediction_rfc = rfc.predict(user_input)\n",
    "prediction_lr = lr.predict(user_input)\n",
    "prediction_knn = knn.predict(user_input)\n",
    "prediction_nb = nb.predict(user_input)\n",
    "# Return the predictions\n",
    "print(\"Decision Tree Prediction:\", prediction_dtc[0])\n",
    "print(\"Random Forest Prediction:\", prediction_rfc[0])\n",
    "print(\"Logistic Regression Prediction:\", prediction_lr[0])\n",
    "print(\"KNeighborsClassifier:\", prediction_knn[0])\n",
    "print(\"GaussianNB:\", prediction_nb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242d6295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9\n",
      "Random Forest Accuracy: 1.0\n",
      "Logistic Regression Accuracy: 0.95\n",
      "KNeighborsClassifier Accuracy: 0.95\n",
      "GaussianNB Accuracy: 1.0\n",
      "Enter the value for N: 13\n",
      "Enter the value for K: 0\n",
      "Enter the value for P: 0\n",
      "\n",
      "Predictions:\n",
      "Decision Tree Prediction: 20-20\n",
      "Random Forest Prediction: 20-20\n",
      "Logistic Regression Prediction: 20-20\n",
      "KNeighborsClassifier Prediction: 20-20\n",
      "GaussianNB Prediction: 20-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_excel(r\"C:\\Users\\Admin\\Desktop\\KT\\NPK.xlsx\")\n",
    "\n",
    "# Splitting the data into input and output variables\n",
    "X = data.iloc[:, :3]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "lr = LogisticRegression(random_state=0)\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "nb.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "y_pred_dtc = dtc.predict(X_test)\n",
    "accuracy_dtc = accuracy_score(y_test, y_pred_dtc)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_dtc)\n",
    "\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "accuracy_rfc = accuracy_score(y_test, y_pred_rfc)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rfc)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_lr)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"KNeighborsClassifier Accuracy:\", accuracy_knn)\n",
    "\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(\"GaussianNB Accuracy:\", accuracy_nb)\n",
    "\n",
    "# User inputs\n",
    "N = input(\"Enter the value for N: \")\n",
    "K = input(\"Enter the value for K: \")\n",
    "P = input(\"Enter the value for P: \")\n",
    "\n",
    "N = int(N)\n",
    "K = int(K)\n",
    "P = int(P)\n",
    "\n",
    "# User inputs\n",
    "user_input = [[N, K, P]]\n",
    "\n",
    "# Make predictions using each model\n",
    "prediction_dtc = dtc.predict(user_input)\n",
    "prediction_rfc = rfc.predict(user_input)\n",
    "prediction_lr = lr.predict(user_input)\n",
    "prediction_knn = knn.predict(user_input)\n",
    "prediction_nb = nb.predict(user_input)\n",
    "\n",
    "# Return the predictions\n",
    "print(\"\\nPredictions:\")\n",
    "print(\"Decision Tree Prediction:\", prediction_dtc[0])\n",
    "print(\"Random Forest Prediction:\", prediction_rfc[0])\n",
    "print(\"Logistic Regression Prediction:\", prediction_lr[0])\n",
    "print(\"KNeighborsClassifier Prediction:\", prediction_knn[0])\n",
    "print(\"GaussianNB Prediction:\", prediction_nb[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba18eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vc = VotingClassifier(estimators=[\n",
    "    ('decision_tree', dtc),\n",
    "    ('random_forest', rfc),\n",
    "    ('KNeighborsClassifier', knn),\n",
    "    ('GaussianNB', nb),\n",
    "    ('logistic_regression', lr)\n",
    "], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57dc07b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename='savemodel1.sav'\n",
    "pickle.dump(vc,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86282fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model=pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a53f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
